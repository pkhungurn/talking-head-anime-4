<html lang="en">
    <head>
        <title>
            Supplementary Material for "Talking Head Anime 4: Distillation for Real-Time Performance"
        </title>
    </head>    
    <body>
        <center><h1>Supplementary material for "Talking Head Anime 4: Distillation for Real-Time Performance"</h1></center>

        <h2>1 &nbsp; Implementation Details</h2>

        <p>Details about model architectures, training setups, and computer used for evaluation can be found in <a href="supplementary.pdf"><code>supplementary.pdf</code></a>.</p>

        <h2>2 &nbsp; Comparison Videos</h2>

        <p>We show comparisons between animations generated by the THA3 baseline, the teacher model, and the student models on the 3 characters used for evaluation in Section 4 of the paper below.</p>

        <h3>Character #1</h3>

        <p><video src="videos/compare/taoist_boy/video_for_web.mp4" controls></video></p>
        
        <p><video src="videos/compare_face_crop/taoist_boy/video_for_web.mp4" controls></video></p>        

        <h3>Character #2</h3>

        <p><video src="videos/compare/koakuma_mei/video_for_web.mp4" controls></video></p>
        
        <p><video src="videos/compare_face_crop/koakuma_mei/video_for_web.mp4" controls></video></p>        

        <h3>Character #3</h3>

        <p><video src="videos/compare/marietta/video_for_web.mp4" controls></video></p>        

        <p><video src="videos/compare_face_crop/marietta/video_for_web.mp4" controls></video></p>

        <h2>3 &nbsp; Videos for qualitative evaluations against THA3 and other systems</h2>

        <p>For qualitative comparisons, we used the systems to animate pictures of anime characters in the wild.</p>

        <p>We do not have 3D models for these characters to generate groundtruths to compute metrics or generate stick-figure videos to drive AnimateAnyone. As a result, we used <a href="https://www.deviantart.com/yoshxxxmmd/art/MMD-Yozora-Mel-1022383203">a 3D model of a VTuber</a> that do not match the identity of the characters to drive AnimateAnyone, and we used the actor video to drive LivePortrait. Identity mismatch between the image being animated and the controlling video is an inherent problem to such systems. However, THA3 and our systems circumvent this problem by controlling images through pose vectors, which are independent of identities.</p>

        <h3>3.1 &nbsp; Character 1</h3>

        <table cellpadding="5" border="1">
            <tr>
                <td>Image being animated by LivePortrait</td>
                <td>Image being animated by other systems</td>
            </tr>
            <tr>
                <td align="center"><a href="videos/compare_with_other_works/touhoku_zunko/touhoku_zunko_cropped.png"><img src="videos/compare_with_other_works/touhoku_zunko/touhoku_zunko_cropped.png" width="200"></a></td>
                <td align="center"><a href="videos/compare_with_other_works/touhoku_zunko/touhoku_zunko.png"><img src="videos/compare_with_other_works/touhoku_zunko/touhoku_zunko.png" width="200"></a></td>
            </tr>                        
        </table>

        <p>Comparison between outputs generated by the systems.</p>

        <video width="800" controls>
            <source src="videos/compare_with_other_works/touhoku_zunko/video_for_web.mp4" type="video/mp4">            
        </video>

        <h3>3.2 &nbsp; Character 2</h3>

        <table cellpadding="5" border="1">
            <tr>
                <td>Image being animated by LivePortrait</td>
                <td>Image being animated by other systems</td>
            </tr>
            <tr>
                <td align="center"><a href="videos/compare_with_other_works/touhoku_itako/touhoku_itako_cropped.png"><img src="videos/compare_with_other_works/touhoku_itako/touhoku_itako_cropped.png" width="200"></a></td>
                <td align="center"><a href="videos/compare_with_other_works/touhoku_itako/touhoku_itako.png"><img src="videos/compare_with_other_works/touhoku_itako/touhoku_itako.png" width="200"></a></td>
            </tr>                        
        </table>

        <p>Comparison between outputs generated by the systems.</p>

        <video width="800" controls>
            <source src="videos/compare_with_other_works/touhoku_itako/video_for_web.mp4" type="video/mp4">            
        </video>

        <h3>3.3 &nbsp; Character 3</h3>

        <table cellpadding="5" border="1">
            <tr>
                <td>Image being animated by LivePortrait</td>
                <td>Image being animated by other systems</td>
            </tr>
            <tr>
                <td align="center"><a href="videos/compare_with_other_works/lambda_san/lambda_san_cropped.png"><img src="videos/compare_with_other_works/lambda_san/lambda_san_cropped.png" width="200"></a></td>
                <td align="center"><a href="videos/compare_with_other_works/lambda_san/lambda_san.png"><img src="videos/compare_with_other_works/lambda_san/lambda_san.png" width="200"></a></td>
            </tr>                        
        </table>

        <p>Comparison between outputs generated by the systems.</p>

        <video width="800" controls>
            <source src="videos/compare_with_other_works/lambda_san/video_for_web.mp4" type="video/mp4">            
        </video>

        
        <h2>4 &nbsp; Demos</h2>

        <p>We provide web-based two demos where the user can control characters in real-time.</p>

        <ul>
            <li>The <a href="manual-poser-demo/index.html">first demo</a> allows the user to control characters by manipulating sliders.</li>
            <li>The <a href="webcam-demo/index.html">second demo</a> directory allows the user to control characters with their facial movement, captured by a web camera.</li>
        </ul>

        <p>The demos requires a PC with a moderately powerful GPU to run. The <code>webcam-demo</code>, of course, requires a web camera.</p>            
    </body>
</html>